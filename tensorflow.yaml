# apiVersion: v1
# kind: PersistentVolumeClaim
# metadata:
#   name: tensorvol
# spec:
#   storageClassName: rook-block
#   accessModes:
#   - ReadWriteOnce
#   resources:
#     requests:
#       storage: 200Gi
# ---
kind: Pod
apiVersion: v1
metadata:
  name: gpu-pod
spec:
  containers:
  - name: gpu-container
    image: gcr.io/tensorflow/tensorflow:latest-gpu
    imagePullPolicy: Always
    #command: ["python"]
    #args: ["-u", "-c", "import tensorflow"]
    args: ["sleep", "36500000"]
    resources:
      limits:
        alpha.kubernetes.io/nvidia-gpu: 5
      requests:
        alpha.kubernetes.io/nvidia-gpu: 5
    volumeMounts:
    - name: nvidia-driver-384-90
      mountPath: /usr/local/nvidia
      readOnly: true
    - name: libcuda-so
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so
    - name: libcuda-so-1
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.1
    - name: libcuda-so-384-90
      mountPath: /usr/lib/x86_64-linux-gnu/libcuda.so.384.90/
    # - mountPath: /tensorvol
    #   name: tensorvol
    - mountPath: /examples
      name: tensor-examples
  restartPolicy: Never
  nodeSelector:
    kubernetes.io/hostname: k8s-gpu-01.calit2.optiputer.net
  volumes:
    - name: nvidia-driver-384-90
      hostPath:
        path: /var/lib/nvidia-docker/volumes/nvidia_driver/384.90/
    - name: libcuda-so
      hostPath:
        path: /usr/lib/x86_64-linux-gnu/libcuda.so
    - name: libcuda-so-1
      hostPath:
        path: /usr/lib/x86_64-linux-gnu/libcuda.so.1
    - name: libcuda-so-384-90
      hostPath:
        path: /usr/lib/x86_64-linux-gnu/libcuda.so.384.90/
    - name: tensor-examples
      gitRepo:
        repository: "https://github.com/tensorflow/models.git"
